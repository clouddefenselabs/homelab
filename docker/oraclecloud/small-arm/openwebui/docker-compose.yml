services:

  openWebUI:
    image: ghcr.io/open-webui/open-webui:0.4.6
    restart: always
    ports:
      - "3002:8080"
    environment:
      - 'OLLAMA_BASE_URL=http://172.16.100.10:11434' 
    #extra_hosts:
    #  - "host.docker.internal:host-gateway"
    volumes:
      - open-webui-local:/app/backend/data


  pipelines:
    image: ghcr.io/open-webui/pipelines:main
    ports:
      - "9099:9099"
    volumes:
      - pipelines:/app/pipelines
    restart: always

  ollama-local:
    image: ghcr.io/ollama/ollama:latest
    container_name: ollama-local
    restart: always
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/ollama/data
    environment:
      - OLLAMA_CONFIG_PATH=/ollama/config

volumes:
  pipelines:
    external: true
  open-webui-local:
    external: true
  ollama-data:
    external: true
